{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Tuple\n",
    "from sympy import Ci\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from mindiffusion.unet import NaiveUnet\n",
    "from mindiffusion.ddpm import DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapsDataset(Dataset):\n",
    "    \"\"\" Highway maps dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.im_names = os.listdir(self.root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.im_names[idx])\n",
    "        image =torchvision.io.read_image(img_name)/255\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_maps(\n",
    "   path_to_dir, n_epoch: int = 100, device: str = \"cuda:0\",\n",
    "   load_pth: Optional[str] = None , Flip: bool = False,\n",
    "   lr: float = 5e-5\n",
    ") -> None:\n",
    "\n",
    "    ddpm = DDPM(eps_model=NaiveUnet(3, 3, n_feat=128), betas=(1e-4, 0.02), n_T=1000)\n",
    "\n",
    "    if load_pth is not None:\n",
    "        ddpm.load_state_dict(torch.load(load_pth))\n",
    "\n",
    "    ddpm.to(device)\n",
    "    if Flip:\n",
    "        tf = transforms.Compose(\n",
    "            [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "             transforms.RandomVerticalFlip(),\n",
    "             transforms.RandomHorizontalFlip()\n",
    "            ])\n",
    "    else:\n",
    "         tf = transforms.Compose(\n",
    "    [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "\n",
    "    maps_dataset = MapsDataset(root_dir = path_to_dir,\n",
    "                   transform = tf\n",
    "                   )\n",
    "\n",
    "    dataloader = DataLoader(maps_dataset, batch_size=128,\n",
    "                            shuffle=True, num_workers=2)\n",
    "    optim = torch.optim.Adam(ddpm.parameters(), lr=lr)\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "        print(f\"Epoch {i} : \")\n",
    "        ddpm.train()\n",
    "\n",
    "        pbar = tqdm(dataloader)\n",
    "        loss_ema = None\n",
    "        for x in pbar:\n",
    "            optim.zero_grad()\n",
    "            x = x.to(device)\n",
    "            loss = ddpm(x)\n",
    "            loss.backward()\n",
    "            if loss_ema is None:\n",
    "                loss_ema = loss.item()\n",
    "            else:\n",
    "                loss_ema = 0.96 * loss_ema + 0.04 * loss.item()\n",
    "            pbar.set_description(f\"loss: {loss_ema:.4f}\")\n",
    "            optim.step()\n",
    "\n",
    "        ddpm.eval()\n",
    "        with torch.no_grad():\n",
    "            if (i+1)%10 ==0:\n",
    "                xh = ddpm.sample(8, (3, 64, 64), device)\n",
    "                xset = torch.cat([xh, x[:8]], dim=0)\n",
    "                grid = make_grid(xset, normalize=True, nrow=4, scale_each=True)\n",
    "                save_image(grid, f\"ddpm_sample_maps_10000_{i}.png\")\n",
    "\n",
    "            # save model\n",
    " \n",
    "            torch.save(ddpm.state_dict(),\"./data/ddpm_maps_10000.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dir = \"./data/my_dataset\"\n",
    "load_pth = \"./data/ddpm_maps_10000.pth\"\n",
    "train_maps(path_to_dir,Flip = True,load_pth = load_pth,n_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dir = \"./data/my_dataset\"\n",
    "load_pth = \"./data/ddpm_maps_10000.pth\"\n",
    "train_maps(path_to_dir,Flip = True,load_pth = load_pth,n_epoch = 10,lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "ddpm = DDPM(eps_model=NaiveUnet(3, 3, n_feat=128), betas=(1e-4, 0.02), n_T=1000)\n",
    "\n",
    "ddpm.load_state_dict(torch.load(\"./data/ddpm_maps_10000.pth\"))\n",
    "\n",
    "ddpm.to(device)\n",
    "\n",
    "ddpm.eval()\n",
    "with torch.no_grad():\n",
    "    xh = ddpm.sample(25, (3, 64, 64), device)\n",
    "    xset = torch.cat([xh], dim=0)\n",
    "    grid = make_grid(xset, normalize=True, nrow=5,scale_each= True)\n",
    "    save_image(grid, f\"ddpm_sample_maps.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
